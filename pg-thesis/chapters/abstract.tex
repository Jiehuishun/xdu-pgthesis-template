With the rapid development of artificial intelligence technology, the application of multi-modal large 
models in complex interaction scenarios has gradually attracted attention. As a typical high-frequency, 
multi-modal interactive scenario, the KFC ordering scenario involves the processing of multiple 
information such as voice, text, and image, which poses new challenges and opportunities for the 
post-training of large models. This paper focuses on the post-training research of multi-modal large 
models for KFC ordering, aiming to improve the intelligence level and user experience of the ordering 
system by optimizing the model's understanding and generation ability of multimodal information. By 
systematically analyzing the multimodal post-training strategy and combining it with experimental 
verification, this paper provides theoretical support and practical guidance for the application of 
large models in the fast food industry, and also provides new ideas for model optimization in multimodal 
interaction scenarios.